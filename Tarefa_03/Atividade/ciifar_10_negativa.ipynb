{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 567,
     "status": "ok",
     "timestamp": 1673271298350,
     "user": {
      "displayName": "Pedro Azevedo",
      "userId": "10851796167437368902"
     },
     "user_tz": 180
    },
    "id": "I3SimwbJsUoO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.io import imread,imsave, imshow\n",
    "from skimage.color import rgb2gray, gray2rgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imread,imsave\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1673271298991,
     "user": {
      "displayName": "Pedro Azevedo",
      "userId": "10851796167437368902"
     },
     "user_tz": 180
    },
    "id": "0YQEvP5ssYEO"
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1673271300432,
     "user": {
      "displayName": "Pedro Azevedo",
      "userId": "10851796167437368902"
     },
     "user_tz": 180
    },
    "id": "XfC1DiwWshs5",
    "outputId": "7d21cf33-b0b8-4bfe-dad6-cb517d952259"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1673271300982,
     "user": {
      "displayName": "Pedro Azevedo",
      "userId": "10851796167437368902"
     },
     "user_tz": 180
    },
    "id": "fSRZxLkAsweh"
   },
   "outputs": [],
   "source": [
    "def negativa(imagem):\n",
    "    altura, largura = imagem.shape[:2]\n",
    "    for i in range(altura):\n",
    "        for j in range(largura):\n",
    "            imagem[i, j] = 255 - imagem[i, j]\n",
    "    return imagem\n",
    "\n",
    "def negative_s1mple(image):\n",
    "    return 255 - image\n",
    "\n",
    "class negativa_torch(object):\n",
    "\n",
    "    def __call__(self, imagem):\n",
    "      imagem = imagem.numpy()\n",
    "      altura, largura = imagem.shape[:2]\n",
    "      for i in range(altura):\n",
    "          for j in range(largura):\n",
    "              imagem[i, j] = 255 - torch.from_numpy(imagem[i, j])\n",
    "      return imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1049,
     "status": "ok",
     "timestamp": 1673271303387,
     "user": {
      "displayName": "Pedro Azevedo",
      "userId": "10851796167437368902"
     },
     "user_tz": 180
    },
    "id": "4gQsZ2LRs4hu",
    "outputId": "8b9fa238-371b-412b-b657-815d4b8df1a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(num_output_channels=1), transforms.ToTensor(), negativa_torch()])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=6,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=6,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "executionInfo": {
     "elapsed": 616,
     "status": "ok",
     "timestamp": 1673271304000,
     "user": {
      "displayName": "Pedro Azevedo",
      "userId": "10851796167437368902"
     },
     "user_tz": 180
    },
    "id": "sarAYGRQ0IWL",
    "outputId": "e095195f-4f0f-40e9-ad0b-ff1171ecc9b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "127.9902\n",
      "(3, 36, 206)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ship   cat   dog  frog\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    print(np.min(npimg))\n",
    "    print(np.max(npimg))\n",
    "    print(npimg.shape)\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "img_transform = images[0]\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 549,
     "status": "ok",
     "timestamp": 1673272199041,
     "user": {
      "displayName": "Pedro Azevedo",
      "userId": "10851796167437368902"
     },
     "user_tz": 180
    },
    "id": "rK1pmD9XunT2"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class classificador(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3))\n",
    "    self.conv2 = nn.Conv2d(32, 32, (3, 3))\n",
    "    self.activation = nn.ReLU()\n",
    "    self.bnorm = nn.BatchNorm2d(num_features=32)\n",
    "    self.pool = nn.MaxPool2d(kernel_size = (2,2))\n",
    "    self.flatten = nn.Flatten()\n",
    "\n",
    "    # output = (input - filter + 1) / stride\n",
    "    # convolução 1: (28 - 3 + 1) / 1 = 30x30\n",
    "    # pooling 1: 15x15\n",
    "    # convolução 2: (15 - 3 + 1) / 1 = 13x13\n",
    "    # pooling 2: 6x6\n",
    "    # 6 * 6 * 32\n",
    "    # 800 -> 128 -> 128 -> 10\n",
    "    self.linear1 = nn.Linear(in_features=32*6*6, out_features=128)\n",
    "    self.linear2 = nn.Linear(128, 128)\n",
    "    self.output = nn.Linear(128, 10)\n",
    "    self.dropout = nn.Dropout(p = 0.2)\n",
    "\n",
    "  def forward(self, X):\n",
    "    X = self.pool(self.bnorm(self.activation(self.conv1(X))))\n",
    "    X = self.pool(self.bnorm(self.activation(self.conv2(X))))\n",
    "    X = self.flatten(X)\n",
    "\n",
    "    X = self.dropout(self.activation(self.linear1(X)))\n",
    "    X = self.dropout(self.activation(self.linear2(X)))\n",
    "    X = self.output(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "net = classificador()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 579,
     "status": "ok",
     "timestamp": 1673272020457,
     "user": {
      "displayName": "Pedro Azevedo",
      "userId": "10851796167437368902"
     },
     "user_tz": 180
    },
    "id": "4vQ46m6Cww32"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 438849,
     "status": "ok",
     "timestamp": 1673272641583,
     "user": {
      "displayName": "Pedro Azevedo",
      "userId": "10851796167437368902"
     },
     "user_tz": 180
    },
    "id": "wg8s-pWk6h7J",
    "outputId": "e16bac72-ef80-49a8-e3e0-bf01d38d5946"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.313\n",
      "[1,  4000] loss: 2.311\n",
      "[1,  6000] loss: 2.315\n",
      "[1,  8000] loss: 2.312\n",
      "[2,  2000] loss: 2.313\n",
      "[2,  4000] loss: 2.312\n",
      "[2,  6000] loss: 2.314\n",
      "[2,  8000] loss: 2.314\n",
      "[3,  2000] loss: 2.316\n",
      "[3,  4000] loss: 2.311\n",
      "[3,  6000] loss: 2.312\n",
      "[3,  8000] loss: 2.312\n",
      "[4,  2000] loss: 2.313\n",
      "[4,  4000] loss: 2.314\n",
      "[4,  6000] loss: 2.313\n",
      "[4,  8000] loss: 2.312\n",
      "[5,  2000] loss: 2.311\n",
      "[5,  4000] loss: 2.314\n",
      "[5,  6000] loss: 2.313\n",
      "[5,  8000] loss: 2.314\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1673272641584,
     "user": {
      "displayName": "Pedro Azevedo",
      "userId": "10851796167437368902"
     },
     "user_tz": 180
    },
    "id": "0mpi99og6jzA"
   },
   "outputs": [],
   "source": [
    "PATH = './cifar_net_negativa.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1673272641585,
     "user": {
      "displayName": "Pedro Azevedo",
      "userId": "10851796167437368902"
     },
     "user_tz": 180
    },
    "id": "LT8kc8Yj6nPP",
    "outputId": "2d716cda-7587-4826-c00a-5e36496e40cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "128.0\n",
      "(3, 36, 206)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:    cat  ship  ship plane\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1673272641585,
     "user": {
      "displayName": "Pedro Azevedo",
      "userId": "10851796167437368902"
     },
     "user_tz": 180
    },
    "id": "Jl_YOqVA6pQc"
   },
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1673272641586,
     "user": {
      "displayName": "Pedro Azevedo",
      "userId": "10851796167437368902"
     },
     "user_tz": 180
    },
    "id": "9EGfA4Rx6qwm",
    "outputId": "1829ecae-3d2e-41a2-a5f2-60e6c46cb8ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  truck truck   car  bird\n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12959,
     "status": "ok",
     "timestamp": 1673272654531,
     "user": {
      "displayName": "Pedro Azevedo",
      "userId": "10851796167437368902"
     },
     "user_tz": 180
    },
    "id": "J2TbrFHJ6seZ",
    "outputId": "97b33e01-d09c-4398-aff7-0dc07331a91a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 9 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12527,
     "status": "ok",
     "timestamp": 1673272667037,
     "user": {
      "displayName": "Pedro Azevedo",
      "userId": "10851796167437368902"
     },
     "user_tz": 180
    },
    "id": "2grCXhrG6umk",
    "outputId": "fe68bb90-fb3b-490a-9963-b7f28cb78f61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane :  6 %\n",
      "Accuracy of   car : 40 %\n",
      "Accuracy of  bird : 17 %\n",
      "Accuracy of   cat :  0 %\n",
      "Accuracy of  deer :  1 %\n",
      "Accuracy of   dog : 10 %\n",
      "Accuracy of  frog :  0 %\n",
      "Accuracy of horse :  0 %\n",
      "Accuracy of  ship :  1 %\n",
      "Accuracy of truck : 22 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1673272667039,
     "user": {
      "displayName": "Pedro Azevedo",
      "userId": "10851796167437368902"
     },
     "user_tz": 180
    },
    "id": "vRyhcdEJ6wVY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
